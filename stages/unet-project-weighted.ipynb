{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.41.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.18.1)\n",
      "Requirement already satisfied: keras~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (58.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 14:11:54.123258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-24 14:11:54.123307: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Layer, InputSpec\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neptune-client in /opt/conda/lib/python3.7/site-packages (0.13.0)\n",
      "Requirement already satisfied: neptune-tensorflow-keras in /opt/conda/lib/python3.7/site-packages (0.9.9)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (8.3.2)\n",
      "Requirement already satisfied: bravado in /opt/conda/lib/python3.7/site-packages (from neptune-client) (11.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (1.15.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from neptune-client) (5.8.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (0.18.2)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (2.25.1)\n",
      "Requirement already satisfied: jsonschema<4 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (3.2.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from neptune-client) (1.3.4)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (8.0.3)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (0.57.0)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (3.1.24)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from neptune-client) (21.0)\n",
      "Requirement already satisfied: PyJWT in /opt/conda/lib/python3.7/site-packages (from neptune-client) (2.3.0)\n",
      "Requirement already satisfied: boto3>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (1.19.7)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (1.3.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from neptune-client) (1.26.7)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.0->neptune-client) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.7 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.0->neptune-client) (1.22.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.0->neptune-client) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.0->neptune-client) (4.8.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=2.0.8->neptune-client) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=2.0.8->neptune-client) (3.7.4.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4->neptune-client) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4->neptune-client) (21.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema<4->neptune-client) (58.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->neptune-client) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->neptune-client) (4.0.0)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client) (1.0.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client) (6.0)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client) (5.17.0)\n",
      "Requirement already satisfied: monotonic in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client) (1.6)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client) (2.8.2)\n",
      "Requirement already satisfied: simplejson in /opt/conda/lib/python3.7/site-packages (from bravado->neptune-client) (3.17.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->neptune-client) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->neptune-client) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas->neptune-client) (1.19.5)\n",
      "Requirement already satisfied: jsonref in /opt/conda/lib/python3.7/site-packages (from bravado-core>=5.16.1->bravado->neptune-client) (0.2)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.7.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.0->neptune-client) (3.6.0)\n",
      "Requirement already satisfied: rfc3987 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4->neptune-client) (1.3.8)\n",
      "Requirement already satisfied: strict-rfc3339 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4->neptune-client) (0.7)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4->neptune-client) (2.1)\n",
      "Requirement already satisfied: webcolors in /opt/conda/lib/python3.7/site-packages (from jsonschema<4->neptune-client) (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install neptune-client neptune-tensorflow-keras\n",
    "\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info (NVML): NVML Shared Library Not Found. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/denissimo/UNET-X/e/UNET-20\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"denissimo/UNET-X\",\n",
    "    tags=['unet', 'binary_ce', 'weighted', 'pretrained_on_binary_ce'],\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiYzYyNmYyMC02YmVkLTRjN2QtYmY5ZC00NDdmZDBhODMxNTIifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'dataset_path': './data'\n",
    "}\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "NUM_SAMPLES = 3075\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "CLASS_WEIGHTS = np.array([0.0038977 , 0.08838018, 0.90772211])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(f'{CFG[\"dataset_path\"]}/y_train.npy')\n",
    "x = np.load(f'{CFG[\"dataset_path\"]}/x_train.npy')\n",
    "\n",
    "slice_invalid = [950, 993, 994, 995, 996, 997, 998, 999]\n",
    "\n",
    "x = np.delete(x, slice_invalid, axis=0)\n",
    "y = np.delete(y, slice_invalid, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Common code samples\n",
    "\n",
    "### * Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ohe(sample, index_shape, n_classes):\n",
    "    new_shape = (*index_shape, n_classes)\n",
    "    responce_tensor = np.zeros(new_shape)\n",
    "    for img_class in range(n_classes):\n",
    "        responce_tensor[:,:,:,img_class] = (sample == img_class).reshape(index_shape)\n",
    "    return responce_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ohe = apply_ohe(y, (NUM_SAMPLES, IMG_HEIGHT, IMG_WIDTH), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def weighted_binary_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = (y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred)) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 14:12:05.330107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-24 14:12:05.330157: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-24 14:12:05.330179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sample): /proc/driver/nvidia/version does not exist\n",
      "2021-11-24 14:12:05.330517: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "custom_loss = weighted_binary_crossentropy(CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def IoU_class_0(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,0])\n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,0])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def IoU_class_1(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,1])\n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,1])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def IoU_class_2(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,2])\n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,2])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
    "#Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.2)(c1)  # Original 0.1\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.2)(c2)  # Original 0.1\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.2)(c8)  # Original 0.1\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.2)(c9)  # Original 0.1\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='sigmoid')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[IoU, 'accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return multi_unet_model(n_classes=3, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "# model.compile(optimizer='adam', loss=custom_loss, metrics=[IoU, 'accuracy', IoU_class_0, IoU_class_1, IoU_class_2])\n",
    "# model.summary()\n",
    "\n",
    "model = tf.keras.models.load_model('unet_tasks_binary_ce.h5', \n",
    "    custom_objects={\n",
    "        'IoU': IoU,\n",
    "        'IoU_class_0': IoU_class_0,\n",
    "        'IoU_class_1': IoU_class_1,\n",
    "        'IoU_class_2': IoU_class_2,\n",
    "    })\n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=[IoU, 'accuracy', IoU_class_0, IoU_class_1, IoU_class_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run['model/method'] = 'adam'\n",
    "run['model/loss'] = 'weighted_binary_crossentropy'\n",
    "run['model/batchsize'] = 64\n",
    "run['model/epochs'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, save_path, batch_size, epochs, model_name=\"\"):\n",
    "    model_name += datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    earlystopper = EarlyStopping(patience=50, verbose=1)\n",
    "    checkpointer = ModelCheckpoint(save_path, verbose=1, save_best_only=False)\n",
    "\n",
    "    log_dir = \"./\" + model_name\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
    "\n",
    "    results = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=batch_size, epochs=epochs,\n",
    "                        callbacks=[earlystopper, checkpointer\n",
    "                                 , neptune_cbk\n",
    "                            ], workers=16)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 14:12:10.774300: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 435s 19s/step - loss: 0.0441 - IoU: 0.9187 - accuracy: 0.9663 - IoU_class_0: 0.9574 - IoU_class_1: 0.4727 - IoU_class_2: 0.0374 - val_loss: 0.0305 - val_IoU: 0.8963 - val_accuracy: 0.9773 - val_IoU_class_0: 0.9497 - val_IoU_class_1: 0.3648 - val_IoU_class_2: 0.0144\n",
      "\n",
      "Epoch 00001: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 430s 20s/step - loss: 0.0208 - IoU: 0.9396 - accuracy: 0.9821 - IoU_class_0: 0.9672 - IoU_class_1: 0.5991 - IoU_class_2: 0.0297 - val_loss: 0.0250 - val_IoU: 0.9233 - val_accuracy: 0.9790 - val_IoU_class_0: 0.9659 - val_IoU_class_1: 0.4583 - val_IoU_class_2: 0.0297\n",
      "\n",
      "Epoch 00002: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 431s 20s/step - loss: 0.0146 - IoU: 0.9597 - accuracy: 0.9867 - IoU_class_0: 0.9809 - IoU_class_1: 0.6943 - IoU_class_2: 0.0720 - val_loss: 0.0229 - val_IoU: 0.9321 - val_accuracy: 0.9805 - val_IoU_class_0: 0.9675 - val_IoU_class_1: 0.5375 - val_IoU_class_2: 0.0534\n",
      "\n",
      "Epoch 00003: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 439s 20s/step - loss: 0.0106 - IoU: 0.9693 - accuracy: 0.9888 - IoU_class_0: 0.9853 - IoU_class_1: 0.7624 - IoU_class_2: 0.1268 - val_loss: 0.0203 - val_IoU: 0.9370 - val_accuracy: 0.9819 - val_IoU_class_0: 0.9698 - val_IoU_class_1: 0.5539 - val_IoU_class_2: 0.0721\n",
      "\n",
      "Epoch 00004: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 429s 20s/step - loss: 0.0040 - IoU: 0.9824 - accuracy: 0.9940 - IoU_class_0: 0.9911 - IoU_class_1: 0.8417 - IoU_class_2: 0.6089 - val_loss: 0.0142 - val_IoU: 0.9663 - val_accuracy: 0.9865 - val_IoU_class_0: 0.9831 - val_IoU_class_1: 0.6972 - val_IoU_class_2: 0.3551\n",
      "\n",
      "Epoch 00032: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 431s 20s/step - loss: 0.0040 - IoU: 0.9821 - accuracy: 0.9939 - IoU_class_0: 0.9909 - IoU_class_1: 0.8396 - IoU_class_2: 0.6184 - val_loss: 0.0161 - val_IoU: 0.9684 - val_accuracy: 0.9865 - val_IoU_class_0: 0.9841 - val_IoU_class_1: 0.7091 - val_IoU_class_2: 0.3611\n",
      "\n",
      "Epoch 00033: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 430s 20s/step - loss: 0.0040 - IoU: 0.9824 - accuracy: 0.9939 - IoU_class_0: 0.9910 - IoU_class_1: 0.8424 - IoU_class_2: 0.6132 - val_loss: 0.0162 - val_IoU: 0.9682 - val_accuracy: 0.9865 - val_IoU_class_0: 0.9840 - val_IoU_class_1: 0.7068 - val_IoU_class_2: 0.3581\n",
      "\n",
      "Epoch 00034: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 428s 19s/step - loss: 0.0039 - IoU: 0.9824 - accuracy: 0.9940 - IoU_class_0: 0.9911 - IoU_class_1: 0.8424 - IoU_class_2: 0.6216 - val_loss: 0.0161 - val_IoU: 0.9623 - val_accuracy: 0.9846 - val_IoU_class_0: 0.9812 - val_IoU_class_1: 0.6611 - val_IoU_class_2: 0.3578\n",
      "\n",
      "Epoch 00035: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 429s 19s/step - loss: 0.0039 - IoU: 0.9824 - accuracy: 0.9940 - IoU_class_0: 0.9911 - IoU_class_1: 0.8417 - IoU_class_2: 0.6203 - val_loss: 0.0158 - val_IoU: 0.9683 - val_accuracy: 0.9869 - val_IoU_class_0: 0.9842 - val_IoU_class_1: 0.7047 - val_IoU_class_2: 0.3574\n",
      "\n",
      "Epoch 00036: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 431s 20s/step - loss: 0.0039 - IoU: 0.9827 - accuracy: 0.9941 - IoU_class_0: 0.9912 - IoU_class_1: 0.8438 - IoU_class_2: 0.6216 - val_loss: 0.0167 - val_IoU: 0.9642 - val_accuracy: 0.9850 - val_IoU_class_0: 0.9821 - val_IoU_class_1: 0.6737 - val_IoU_class_2: 0.3682\n",
      "\n",
      "Epoch 00037: saving model to unet_tasks_weighted_binary_ce.h5\n",
      "Epoch 38/100\n",
      "12/22 [===============>..............] - ETA: 3:16 - loss: 0.0040 - IoU: 0.9822 - accuracy: 0.9939 - IoU_class_0: 0.9910 - IoU_class_1: 0.8425 - IoU_class_2: 0.6282"
     ]
    }
   ],
   "source": [
    "train_model(model, x, y_ohe, 'unet_tasks_weighted_binary_ce.h5', 128, 100, 'fcn_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
